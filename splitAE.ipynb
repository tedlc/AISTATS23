{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "from utils import load_mnist_data, Encoder\n",
    "from multiviewdata.torchdatasets import SplitMNIST, NoisyMNIST\n",
    "from torch.utils.data import Subset\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from cca_zoo.deepmodels import architectures\n",
    "from cca_zoo.deepmodels import SplitAE\n",
    "import pytorch_lightning as pl\n",
    "# print(\"PyTorch Version: \",torch.__version__)\n",
    "# print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  print(\"Using the GPU!\")\n",
    "else:\n",
    "  print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_loader, val_loader, train_labels, val_labels=load_mnist_data(n_train=50000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'views': [tensor([[[[-0.0277, -0.0128,  0.0529,  ..., -0.1071,  0.0297,  0.0685],\n",
      "          [-0.0608,  0.2138, -0.0134,  ..., -0.0385,  0.2101, -0.0946],\n",
      "          [-0.2048,  0.0058, -0.0760,  ...,  0.0263,  0.0108,  0.0236],\n",
      "          ...,\n",
      "          [ 0.0256, -0.0344,  0.0824,  ...,  0.1161, -0.0026,  0.0530],\n",
      "          [ 0.1644, -0.1008, -0.0312,  ..., -0.0516, -0.0094,  0.0442],\n",
      "          [-0.1476, -0.0927, -0.2258,  ..., -0.0992,  0.0943, -0.1539]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0534, -0.0844, -0.0668,  ..., -0.1067, -0.0145, -0.0138],\n",
      "          [ 0.0480, -0.0720,  0.0509,  ..., -0.1103, -0.0909, -0.1467],\n",
      "          [ 0.0272, -0.2718,  0.0696,  ..., -0.1862,  0.0602, -0.0708],\n",
      "          ...,\n",
      "          [-0.1228, -0.1551, -0.0610,  ..., -0.1972,  0.0978,  0.0144],\n",
      "          [ 0.0133, -0.1500,  0.0536,  ...,  0.0904, -0.0208, -0.0930],\n",
      "          [ 0.0982, -0.0591, -0.0140,  ..., -0.1193,  0.2122, -0.2344]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0908, -0.0025,  0.1479,  ...,  0.3053, -0.0750, -0.0797],\n",
      "          [-0.0225, -0.1036,  0.0172,  ..., -0.0941, -0.1043, -0.0470],\n",
      "          [ 0.0186, -0.0500,  0.0957,  ...,  0.1140,  0.0234, -0.0715],\n",
      "          ...,\n",
      "          [ 0.1514,  0.0602, -0.0407,  ...,  0.0768, -0.0577, -0.0040],\n",
      "          [-0.0853, -0.0750, -0.0528,  ...,  0.0225,  0.0211, -0.0751],\n",
      "          [-0.0710,  0.0506,  0.0292,  ..., -0.1749, -0.0117,  0.0232]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2119,  0.0529, -0.0256,  ...,  0.0830, -0.0521, -0.1052],\n",
      "          [ 0.0468, -0.0752,  0.1043,  ..., -0.1691, -0.1426,  0.0372],\n",
      "          [ 0.2092, -0.0029, -0.0570,  ..., -0.0288, -0.0646, -0.0969],\n",
      "          ...,\n",
      "          [-0.1523, -0.0608, -0.1159,  ...,  0.1326, -0.0078, -0.0894],\n",
      "          [ 0.1231, -0.0976,  0.0723,  ..., -0.1413,  0.1039,  0.0189],\n",
      "          [-0.1351,  0.0260, -0.0221,  ..., -0.0005, -0.1322, -0.0940]]],\n",
      "\n",
      "\n",
      "        [[[-0.1493, -0.0862, -0.0482,  ..., -0.0653,  0.1186, -0.0144],\n",
      "          [ 0.0053,  0.0140,  0.0283,  ...,  0.0663,  0.1163, -0.0075],\n",
      "          [-0.1883, -0.1364, -0.1698,  ...,  0.1439, -0.0400,  0.1120],\n",
      "          ...,\n",
      "          [-0.0550, -0.1591, -0.0245,  ...,  0.0983,  0.0757,  0.1104],\n",
      "          [-0.1478, -0.0715, -0.0319,  ..., -0.0908,  0.0970,  0.1353],\n",
      "          [ 0.0881, -0.0147,  0.0686,  ..., -0.0102, -0.0483, -0.0628]]],\n",
      "\n",
      "\n",
      "        [[[-0.2496,  0.0804,  0.0199,  ...,  0.0035, -0.0473,  0.1872],\n",
      "          [-0.1891, -0.1104,  0.0532,  ...,  0.0457,  0.1022, -0.0220],\n",
      "          [ 0.0082,  0.0379, -0.0930,  ..., -0.0278, -0.0392, -0.0264],\n",
      "          ...,\n",
      "          [ 0.2006,  0.0077, -0.0401,  ..., -0.1607,  0.1511,  0.0905],\n",
      "          [-0.1090,  0.0592, -0.0605,  ...,  0.0254, -0.1174, -0.1181],\n",
      "          [-0.0023,  0.0516, -0.1644,  ..., -0.0278,  0.0618, -0.0630]]]]), tensor([[[[0.0000, 0.0000, 0.0529,  ..., 0.0000, 0.0297, 0.0685],\n",
      "          [0.0000, 0.2138, 0.0000,  ..., 0.0000, 0.2101, 0.0000],\n",
      "          [0.0000, 0.0058, 0.0000,  ..., 0.0263, 0.0108, 0.0236],\n",
      "          ...,\n",
      "          [0.0256, 0.0000, 0.0824,  ..., 0.1161, 0.0000, 0.0530],\n",
      "          [0.1644, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0442],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0943, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0534, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0480, 0.0000, 0.0509,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0272, 0.0000, 0.0696,  ..., 0.0000, 0.0602, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0978, 0.0144],\n",
      "          [0.0133, 0.0000, 0.0536,  ..., 0.0904, 0.0000, 0.0000],\n",
      "          [0.0982, 0.0000, 0.0000,  ..., 0.0000, 0.2122, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0908, 0.0000, 0.1479,  ..., 0.3053, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0172,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0186, 0.0000, 0.0957,  ..., 0.1140, 0.0234, 0.0000],\n",
      "          ...,\n",
      "          [0.1514, 0.0602, 0.0000,  ..., 0.0768, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0225, 0.0211, 0.0000],\n",
      "          [0.0000, 0.0506, 0.0292,  ..., 0.0000, 0.0000, 0.0232]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.2119, 0.0529, 0.0000,  ..., 0.0830, 0.0000, 0.0000],\n",
      "          [0.0468, 0.0000, 0.1043,  ..., 0.0000, 0.0000, 0.0372],\n",
      "          [0.2092, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1326, 0.0000, 0.0000],\n",
      "          [0.1231, 0.0000, 0.0723,  ..., 0.0000, 0.1039, 0.0189],\n",
      "          [0.0000, 0.0260, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1186, 0.0000],\n",
      "          [0.0053, 0.0140, 0.0283,  ..., 0.0663, 0.1163, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1439, 0.0000, 0.1120],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0983, 0.0757, 0.1104],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0970, 0.1353],\n",
      "          [0.0881, 0.0000, 0.0686,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0804, 0.0199,  ..., 0.0035, 0.0000, 0.1872],\n",
      "          [0.0000, 0.0000, 0.0532,  ..., 0.0457, 0.1022, 0.0000],\n",
      "          [0.0082, 0.0379, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2006, 0.0077, 0.0000,  ..., 0.0000, 0.1511, 0.0905],\n",
      "          [0.0000, 0.0592, 0.0000,  ..., 0.0254, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0516, 0.0000,  ..., 0.0000, 0.0618, 0.0000]]]])], 'label': tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
      "        9, 3]), 'index': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])}\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "  print(x)\n",
    "  break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "encoder=architectures.CNNEncoder(latent_dims=32)\n",
    "decoder_1=architectures.CNNDecoder(latent_dims=32)\n",
    "decoder_2=architectures.CNNDecoder(latent_dims=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "splitAE=SplitAE(latent_dims=32,encoder=encoder,decoders=[decoder_1,decoder_2])\n",
    "trainer=pl.Trainer(max_epochs=20,accelerator='gpu', devices=1,log_every_n_steps=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:110: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  category=PossibleUserWarning,\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | encoder        | CNNEncoder | 25.1 K\n",
      "1 | decoders       | ModuleList | 51.8 K\n",
      "2 | latent_dropout | Dropout    | 0     \n",
      "----------------------------------------------\n",
      "77.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "77.0 K    Total params\n",
      "0.308     Total estimated model params size (MB)\n",
      "C:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74051776d68c4a028b994e78e5e0db3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(splitAE, train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def train_classifier(encoder, cls, dataloader, epochs=100, supervised=False):\n",
    "    encoder=encoder.to(device)\n",
    "    optimizer = optim.Adam(cls.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    if supervised:\n",
    "        optimizer = optim.Adam(list(cls.parameters())+list(encoder.parameters()), lr=0.001, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss_traj = []\n",
    "    accuracy_traj = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        loss_epoch = 0\n",
    "        corrects_epoch = 0\n",
    "        for batch in dataloader:\n",
    "            x,y=batch['views'][0],batch['label']\n",
    "\n",
    "            batch_size = x.size(0)\n",
    "            x = x.float()\n",
    "            x,y=x.to(device),y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            feature = encoder(x.to(device))\n",
    "            outs = cls(feature.view(batch_size,-1))\n",
    "            loss = criterion(outs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outs, 1)\n",
    "            corrects_epoch += torch.sum(preds == y.data)\n",
    "            loss_epoch += loss.detach()\n",
    "\n",
    "        loss_traj.append(loss_epoch)\n",
    "        epoch_acc = corrects_epoch.double() / len(dataloader.dataset)\n",
    "        accuracy_traj.append(epoch_acc)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch {}, loss {:.3f}, train accuracy {}'.format(epoch, loss_epoch, epoch_acc))\n",
    "\n",
    "    return cls, loss_traj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def test(encoder, cls, dataloader):\n",
    "    encoder=encoder.to(device)\n",
    "    cls.eval()\n",
    "\n",
    "    corrects_epoch = 0\n",
    "    for batch in dataloader:\n",
    "        x,y=batch['views'][0],batch['label']\n",
    "\n",
    "        x = x.float()\n",
    "        batch_size = x.size(0)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        h = encoder(x).view(batch_size, -1)\n",
    "        outs = cls(h)\n",
    "        _, preds = torch.max(outs, 1)\n",
    "        corrects_epoch += torch.sum(preds == y.data)\n",
    "\n",
    "    epoch_acc = corrects_epoch.double() / len(dataloader.dataset)\n",
    "    print('Test accuracy {}'.format(epoch_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:01<00:55,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 787.783, train accuracy 0.7867000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [00:14<00:38,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 178.284, train accuracy 0.9463800000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [00:27<00:25,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss 139.894, train accuracy 0.9583200000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [00:39<00:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, loss 126.754, train accuracy 0.9612400000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:49<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.9617\n"
     ]
    }
   ],
   "source": [
    "linear_cls = nn.Sequential(nn.Linear(32, 24),nn.ReLU(),nn.Linear(24,10)).to(device)\n",
    "cls, loss_traj = train_classifier(splitAE.encoder, linear_cls, train_loader, epochs=40, supervised=False)\n",
    "test(splitAE.encoder, cls,val_loader )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}